{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "B4.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNiDMkR2yd2ElK+citFFmSu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BiggusMaximus/AirGap_Scripts/blob/main/B4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "k1He4okMW0A4",
        "outputId": "112c76da-9025-4fbe-f49b-9cfed45cfa10"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-60-c45421deb2c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;31m# DO NOT CHANGE THIS CODE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msolution_B4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"model_B4.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-60-c45421deb2c2>\u001b[0m in \u001b[0;36msolution_B4\u001b[0;34m()\u001b[0m\n\u001b[1;32m     66\u001b[0m     )\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0mtrain_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m     \u001b[0mtest_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m123\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'str' and 'int'"
          ]
        }
      ],
      "source": [
        "# ===================================================================================================\n",
        "# PROBLEM B4\n",
        "#\n",
        "# Build and train a classifier for the BBC-text dataset.\n",
        "# This is a multiclass classification problem.\n",
        "# Do not use lambda layers in your model.\n",
        "#\n",
        "# The dataset used in this problem is originally published in: http://mlg.ucd.ie/datasets/bbc.html.\n",
        "#\n",
        "# Desired accuracy and validation_accuracy > 91%\n",
        "# ===================================================================================================\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def solution_B4():\n",
        "    bbc = pd.read_csv(\n",
        "        'https://github.com/dicodingacademy/assets/raw/main/Simulation/machine_learning/bbc-text.csv')\n",
        "\n",
        "    # DO NOT CHANGE THIS CODE\n",
        "    # Make sure you used all of these parameters or you can not pass this test\n",
        "    vocab_size = 1000\n",
        "    embedding_dim = 16\n",
        "    max_length = 120\n",
        "    trunc_type = 'post'\n",
        "    padding_type = 'post'\n",
        "    oov_tok = \"<OOV>\"\n",
        "    training_portion = .8\n",
        "\n",
        "    # YOUR CODE HERE\n",
        "    # Using \"shuffle=False\"\n",
        "    train_sentences, test_sentences, train_label, test_label = train_test_split(\n",
        "        bbc['text'], \n",
        "        bbc['category'], \n",
        "        train_size=training_portion, \n",
        "        shuffle=False\n",
        "    )\n",
        "\n",
        "    # Fit your tokenizer with training data\n",
        "    tokenizer =  Tokenizer(\n",
        "        num_words=vocab_size, \n",
        "        oov_token=oov_tok\n",
        "    )\n",
        "    tokenizer.fit_on_texts(train_sentences)\n",
        "    word_index = tokenizer.word_index\n",
        "\n",
        "    training_sequences = tokenizer.texts_to_sequences(train_sentences)\n",
        "    training_padded = pad_sequences(\n",
        "        training_sequences, \n",
        "        maxlen=max_length, \n",
        "        padding=padding_type, \n",
        "        truncating=trunc_type\n",
        "    )\n",
        "\n",
        "    testing_sequences = tokenizer.texts_to_sequences(test_sentences)\n",
        "    testing_padded = pad_sequences(\n",
        "        testing_sequences, \n",
        "        maxlen=max_length, \n",
        "        padding=padding_type, \n",
        "        truncating=trunc_type\n",
        "    )\n",
        "\n",
        "    train_label = np.array(train_label)-1\n",
        "    test_label = np.array(test_label)-1\n",
        "    tf.random.set_seed(123)\n",
        "    \n",
        "    ### START CODE HERE\n",
        "    \n",
        "    model = tf.keras.Sequential([ \n",
        "        tf.keras.layers.Embedding(\n",
        "            vocab_size,\n",
        "            embedding_dim, \n",
        "            input_length=max_length),\n",
        "        tf.keras.layers.GlobalAveragePooling1D(),\n",
        "        tf.keras.layers.Dense(24, activation='relu'),\n",
        "        tf.keras.layers.Dense(5, activation='softmax')\n",
        "    ])\n",
        "    \n",
        "    model.compile(loss='sparse_categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy']) \n",
        "    model.fit(\n",
        "        training_padded, \n",
        "        train_label, \n",
        "        epochs=30, \n",
        "        validation_data=(testing_padded, test_label),\n",
        "        verbose=2\n",
        "    )\n",
        "\n",
        "    # Make sure you are using \"sparse_categorical_crossentropy\" as a loss fuction\n",
        "\n",
        "    return model\n",
        "\n",
        "    # The code below is to save your model as a .h5 file.\n",
        "    # It will be saved automatically in your Submission folder.\n",
        "if __name__ == '__main__':\n",
        "    # DO NOT CHANGE THIS CODE\n",
        "    model = solution_B4()\n",
        "    model.save(\"model_B4.h5\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "yGS_J8_n6Nt8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}